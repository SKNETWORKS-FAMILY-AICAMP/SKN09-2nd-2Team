{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë¶„ì„ìš© ë°ì´í„° ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë§í¬\n",
    "\n",
    "https://www.kaggle.com/c/kkbox-churn-prediction-challenge/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:\\\\KIMUJUNG\\\\team_project\\\\data\\\\'\n",
    "df_members = pd.read_csv(data_dir + 'members_v3.csv')\n",
    "train_v1 = pd.read_csv(data_dir + 'train.csv')\n",
    "train_v2 = pd.read_csv(data_dir + 'train_v2.csv')\n",
    "transactions_v1 = pd.read_csv(data_dir + 'transactions.csv')\n",
    "transactions_v2 = pd.read_csv(data_dir + 'transactions_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID ë³€ìˆ˜ì¸ msno ë°”ê¿”ì£¼ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_member = pd.read_csv('C:/ex_data/members_v3.csv')\n",
    "df_member_no = df_member[['msno']].copy()\n",
    "df_member_no.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_member_no['msno_encoded'] = label_encoder.fit_transform(df_member_no['msno']) + 1\n",
    "df_member_no.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# members_encoded.csv íŒŒì¼ ë¡œë“œ\n",
    "df_members = pd.read_csv('C:/ex_data/members_encoded.csv')\n",
    "\n",
    "# msnoì™€ msno_encoded ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ì—¬ ë§¤í•‘ ë§Œë“¤ê¸°\n",
    "msno_mapping = dict(zip(df_members['msno'], df_members['msno_encoded']))\n",
    "msno_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label = pd.read_csv(data_dir + 'members_encoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¡œê·¸ íŒŒì¼ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_logs.csv íŒŒì¼ ë¡œë“œ\n",
    "df_user_logs = pd.read_csv('C:/ex_data/user_logs_v2.csv')\n",
    "\n",
    "# msno ì»¬ëŸ¼ì„ msno_encodedë¡œ ë³€í™˜\n",
    "df_user_logs['msno'] = df_user_logs['msno'].map(msno_mapping).astype('Int64')\n",
    "\n",
    "# csv ì €ìž¥\n",
    "df_user_logs.to_csv('C:/ex_data/user_logs_v2_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_logs_v2_encoded = pd.read_csv('C:/ex_data/user_logs_v2_encoded.csv')\n",
    "df_user_logs_v2_encoded.info(), df_user_logs_v2_encoded.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user_log.csv ì²˜ë¦¬ (chunkë¡œ ë¶„í•  ì²˜ë¦¬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€ìš©ëŸ‰ CSVë¥¼ ë¶„í•  ì²˜ë¦¬í•  í¬ê¸° (ë©”ëª¨ë¦¬ 16ê¸°ê°€ë©´ ë°±ë§Œ, 32ê¸°ê°€ë©´ 3ë°±ë§Œ ê¹Œì§€ ì—¬ìœ ë¡œì›€)\n",
    "chunk_size = 1_000_000  \n",
    "output_file = \"C:/ex_data/user_logs_encoded.csv\"\n",
    "\n",
    "# CSVë¥¼ append ëª¨ë“œë¡œ ì €ìž¥í•˜ê¸° ìœ„í•´ ì²˜ìŒ íŒŒì¼ ìƒì„±\n",
    "first_chunk = True  \n",
    "\n",
    "# ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ í•œ ë²ˆì— ë‹¤ ì½ì§€ ì•Šê³  ë¶€ë¶„ì ìœ¼ë¡œ ì²˜ë¦¬\n",
    "for chunk in pd.read_csv(\"C:/ex_data/user_logs.csv\", chunksize=chunk_size):\n",
    "    chunk['msno'] = chunk['msno'].map(msno_mapping).astype('Int64')  # msnoë¥¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "    # ë³€í™˜ëœ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ìž¥ (ì²« ë²ˆì§¸ ë°˜ë³µì—ì„œëŠ” í—¤ë” í¬í•¨, ì´í›„ì—ëŠ” ìƒëžµ)\n",
    "    chunk.to_csv(output_file, index=False, mode='w' if first_chunk else 'a', header=first_chunk)\n",
    "    \n",
    "    first_chunk = False  # ì´í›„ì—ëŠ” 'append' ëª¨ë“œë¡œ ì €ìž¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2GBì”© ë¶„í• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒë‹¤ìŠ¤ì—ì„œ ì‹¤í–‰í• ë ¤ë©´ íŒŒì¼ í¬ê¸°ê°€ 2GB ì œí•œ\n",
    "chunk_size = 50_000_000  \n",
    "file_index = 1  # íŒŒì¼ ë²ˆí˜¸\n",
    "\n",
    "for chunk in pd.read_csv(\"C:/ex_data/user_logs_encoded.csv\", chunksize=chunk_size):\n",
    "    output_file = f\"C:/ex_data/user_logs_encoded_part{file_index}.csv\"\n",
    "    chunk.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"íŒŒì¼ ì €ìž¥ ì™„ë£Œ: {output_file}\")  # ì €ìž¥ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥\n",
    "    file_index += 1  # ë‹¤ìŒ íŒŒì¼ ë²ˆí˜¸ ì¦ê°€\n",
    "\n",
    "print('íŒŒì¼ ë¶„í•  ì™„ë£Œ!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€í™˜í•  íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
    "file_list = [f\"C:/ex_data/user_logs_encoded_part{i}.csv\" for i in range(1, 9)]\n",
    "\n",
    "for file in file_list:\n",
    "    # CSV íŒŒì¼ ì½ê¸°\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # msno ì»¬ëŸ¼ì„ Int64ë¡œ ë³€í™˜\n",
    "    df['msno'] = df['msno'].astype('Int64')\n",
    "\n",
    "    # ë‹¤ì‹œ ì €ìž¥ (ë®ì–´ì“°ê¸°)\n",
    "    df.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"ë³€í™˜ ì™„ë£Œ: {file}\")\n",
    "\n",
    "print(\"ëª¨ë“  íŒŒì¼ì˜ msnoë¥¼ Int64ë¡œ ë³€í™˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = pd.read_csv(\"C:/ex_data/user_logs_encoded_part7.csv\")\n",
    "split_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (user_logs_v2_encoded.csv + user_logs_encoded_part*.csv í¬í•¨)\n",
    "file_list = [\"C:/ex_data/user_logs_v2_encoded.csv\"] + glob.glob(\"C:/ex_data/user_logs_encoded_part*.csv\")\n",
    "\n",
    "# msnoë³„ ë°ì´í„°ë¥¼ ì €ìž¥í•  ë”•ì…”ë„ˆë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "aggregated_data = {}\n",
    "\n",
    "# ê° íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ê·¸ë£¹í™” & ëˆ„ì \n",
    "for file in file_list:\n",
    "    print(f\"íŒŒì¼ ì²˜ë¦¬ ì¤‘: {file}\")\n",
    "\n",
    "    # CSV íŒŒì¼ ì½ê¸° (ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬)\n",
    "    for chunk in pd.read_csv(file, chunksize=3_000_000):  # ì²­í¬ í¬ê¸° ì¡°ì ˆ ê°€ëŠ¥\n",
    "        # msno ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë°ì´í„° í•©ì‚°\n",
    "        grouped = chunk.groupby(\"msno\").agg(\n",
    "            num_25=(\"num_25\", \"sum\"),\n",
    "            num_50=(\"num_50\", \"sum\"),\n",
    "            num_75=(\"num_75\", \"sum\"),\n",
    "            num_985=(\"num_985\", \"sum\"),\n",
    "            num_100=(\"num_100\", \"sum\"),\n",
    "            num_unq=(\"num_unq\", \"sum\"),\n",
    "            total_secs=(\"total_secs\", \"sum\"),\n",
    "            log_start=(\"date\", \"min\"),  # ê°€ìž¥ ë¹ ë¥¸ ë‚ ì§œ\n",
    "            log_end=(\"date\", \"max\")  # ê°€ìž¥ ë§ˆì§€ë§‰ ë‚ ì§œ\n",
    "        ).reset_index()\n",
    "\n",
    "        # ðŸ— ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©í•˜ì—¬ ëˆ„ì  (ë”•ì…”ë„ˆë¦¬ë¥¼ í™œìš©í•œ ë³‘í•©)\n",
    "        for row in grouped.itertuples(index=False):\n",
    "            msno = row.msno\n",
    "            if msno in aggregated_data:\n",
    "                aggregated_data[msno][\"num_25\"] += row.num_25\n",
    "                aggregated_data[msno][\"num_50\"] += row.num_50\n",
    "                aggregated_data[msno][\"num_75\"] += row.num_75\n",
    "                aggregated_data[msno][\"num_985\"] += row.num_985\n",
    "                aggregated_data[msno][\"num_100\"] += row.num_100\n",
    "                aggregated_data[msno][\"num_unq\"] += row.num_unq\n",
    "                aggregated_data[msno][\"total_secs\"] += row.total_secs\n",
    "                aggregated_data[msno][\"log_start\"] = min(aggregated_data[msno][\"log_start\"], row.log_start)\n",
    "                aggregated_data[msno][\"log_end\"] = max(aggregated_data[msno][\"log_end\"], row.log_end)\n",
    "            else:\n",
    "                aggregated_data[msno] = {\n",
    "                    \"num_25\": row.num_25,\n",
    "                    \"num_50\": row.num_50,\n",
    "                    \"num_75\": row.num_75,\n",
    "                    \"num_985\": row.num_985,\n",
    "                    \"num_100\": row.num_100,\n",
    "                    \"num_unq\": row.num_unq,\n",
    "                    \"total_secs\": row.total_secs,\n",
    "                    \"log_start\": row.log_start,\n",
    "                    \"log_end\": row.log_end\n",
    "                }\n",
    "\n",
    "# ë”•ì…”ë„ˆë¦¬ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ (msnoë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ìœ ì§€)\n",
    "df_final = pd.DataFrame.from_dict(aggregated_data, orient=\"index\")\n",
    "\n",
    "# msnoë¥¼ ì¼ë°˜ ì»¬ëŸ¼ìœ¼ë¡œ ìœ ì§€í•˜ê³  ì¸ë±ìŠ¤ ì œê±°\n",
    "df_final.index.name = \"msno\"\n",
    "df_final.reset_index(inplace=True)\n",
    "\n",
    "# CSV íŒŒì¼ë¡œ ì €ìž¥ (ì¸ë±ìŠ¤ ì—†ì´)\n",
    "df_final.to_csv(\"C:/ex_data/user_logs_summary.csv\", index=False)\n",
    "\n",
    "print(\"ì €ìž¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = pd.read_csv(data_dir + 'user_logs_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v1['version'] = 'v1'\n",
    "train_v2['version'] = 'v2'\n",
    "train = pd.concat([train_v1, train_v2])\n",
    "train = train.sort_values(['msno', 'version'], ascending = [True, False]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = train['msno'][(train['is_churn'] == 0) & (train['version'] == 'v2')]\n",
    "bb = train['msno'][(train['is_churn'] == 1) & (train['version'] == 'v1')]\n",
    "cc = list(set(aa) & set(bb))\n",
    "train['is_back'] = train['msno'].isin(cc).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¤‘ë³µê°’ì„ ì œê±°í•˜ë˜, ì¤‘ë³µ Row ì¤‘ ì²«ë²ˆì§¸ Rowë¥¼ ë‚¨ê¸°ëŠ” ì˜µì…˜ì„ ì„ íƒí•¨\n",
    "train.drop_duplicates(subset='msno', keep='first', inplace=True)\n",
    "train.query('msno in \"+++hVY1rZox/33YtvDgmKA2Frg/2qhkz12B9ylCvh8o=\"')\n",
    "# version ì»¬ëŸ¼ ì œê±°\n",
    "train = train.drop('version', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transaction ë°ì´í„° ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµ¬ë§¤ ê¸°ë¡ ë°ì´í„° í•©ì¹˜ê¸°\n",
    "transactions = pd.concat([transactions_v1, transactions_v2], ignore_index=True)\n",
    "transactions = transactions.sort_values(['msno', 'transaction_date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì˜¤ë¥˜ ë°©ì§€: plan_list_priceê°€ 0ì¸ ê²½ìš°ëŠ” NaN ì²˜ë¦¬\n",
    "transactions[\"discount_rate\"] = np.where(\n",
    "    transactions[\"plan_list_price\"] != 0, \n",
    "    1 - (transactions[\"actual_amount_paid\"] / transactions[\"plan_list_price\"]),\n",
    "    np.nan  # ì›ëž˜ ê°€ê²©ì´ 0ì´ë©´ NaN (ì´í›„ í‰ê·  ê³„ì‚° ì‹œ ìžë™ ì œì™¸ë¨)\n",
    ")\n",
    "\n",
    "# ì‚¬ìš©ìž ID(msno) ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆìž„ ìƒì„±\n",
    "df_transaction = transactions.groupby(\"msno\").agg(\n",
    "    payment_plan_sum=(\"payment_plan_days\", \"sum\"),\n",
    "    plan_list_price=(\"plan_list_price\", \"sum\"),\n",
    "    actual_amount_paid=(\"actual_amount_paid\", \"sum\"),\n",
    "    discount_rate=(\"discount_rate\", \"mean\"),  # ê°œë³„ ê±°ëž˜ë³„ í• ì¸ìœ¨ í‰ê· \n",
    "    is_auto_renew=(\"is_auto_renew\", \"mean\"),\n",
    "    membership_expire_date=(\"membership_expire_date\", \"max\"),\n",
    "    is_cancel=(\"is_cancel\", \"mean\"),\n",
    "    transaction_count=(\"msno\", \"count\")\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ ë°ì´í„°í”„ë ˆìž„ì— msno_num ì¶”ê°€\n",
    "train_en = train.merge(unique_label, on='msno', how='inner').drop(columns=['msno'])\n",
    "members_en = df_members.merge(unique_label, on='msno', how='inner').drop(columns=['msno'])\n",
    "df_transaction_en = df_transaction.merge(unique_label, on='msno', how='inner').drop(columns=['msno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkbox_transaction_merge = pd.merge(train_en, df_transaction_en, on='msno_encoded', how='inner',)\n",
    "kkbox_merge = pd.merge(members_en, kkbox_transaction_merge, on='msno_encoded', how='inner')\n",
    "kkbox_merge['msno'] = kkbox_merge['msno_encoded']\n",
    "kkbox_merge = kkbox_merge[['msno', 'city', 'bd', 'gender', 'registered_via', 'registration_init_time',\n",
    "        'is_churn', 'is_back', 'payment_plan_sum',\n",
    "        'plan_list_price', 'actual_amount_paid', 'discount_rate',\n",
    "        'is_auto_renew', 'membership_expire_date', 'is_cancel', 'transaction_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkbox_merge_final = pd.merge(kkbox_merge, log_data, on='msno', how='inner')\n",
    "kkbox_merge_final.to_csv(data_dir + \"kkbox_data_total.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì„±ë³„ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir + 'kkbox_data_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(df):\n",
    "    # membership_expire_dateì™€ registration_init_timeì€ 'YYYY-MM-DD' í˜•ì‹ìœ¼ë¡œ ë˜ì–´ ìžˆìœ¼ë¯€ë¡œ, ê·¸ì— ë§žì¶° ë³€í™˜\n",
    "    df['membership_expire_date'] = pd.to_datetime(df['membership_expire_date'], errors='coerce')\n",
    "    df['registration_init_time'] = pd.to_datetime(df['registration_init_time'], errors='coerce')\n",
    "    \n",
    "    # log_startì™€ log_endëŠ” 'YYYYMMDD' í˜•ì‹ì´ë¯€ë¡œ, ê·¸ì— ë§žì¶° ë³€í™˜\n",
    "    df['log_start'] = pd.to_datetime(df['log_start'].astype(str), format='%Y%m%d', errors='coerce')\n",
    "    df['log_end'] = pd.to_datetime(df['log_end'].astype(str), format='%Y%m%d', errors='coerce')\n",
    "\n",
    "    # ë“±ë¡ê¸°ê°„ ê³„ì‚°: membership_expire_dateì™€ registration_init_time ì°¨ì´\n",
    "    df['registration_duration'] = (df['membership_expire_date'] - df['registration_init_time']).dt.days\n",
    "\n",
    "    # ìŒì•… ì²­ì·¨ ê¸°ê°„ ê³„ì‚°: log_endì™€ log_start ì°¨ì´\n",
    "    df['listening_duration'] = (df['log_end'] - df['log_start']).dt.days\n",
    "\n",
    "    # í•„ìš” ì—†ëŠ” ì»¬ëŸ¼ ì‚­ì œ\n",
    "    df.drop(['membership_expire_date', 'registration_init_time', 'log_start', 'log_end'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# í•¨ìˆ˜ ì‹¤í–‰\n",
    "df = duration(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['gender'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_gender(df):\n",
    "    # ì„±ë³„ ì¸ì½”ë”©: M -> 1, F -> 0, nan -> -1 (ë˜ëŠ” ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ë³€ê²½)\n",
    "    df['gender'] = df['gender'].map({'male': 1, 'female': 0})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode_gender(df)\n",
    "df['gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë‚˜ì´ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"bd\"] = df[\"bd\"].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"bd\"] >= 10) & (df[\"bd\"] <= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0', 'is_back', 'msno'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì´ìƒì¹˜ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = df[df['payment_plan_sum'].isin([0, 2882, 3550])].index\n",
    "df.drop(aa, inplace=True)\n",
    "bb = df[df['plan_list_price'].isin([0, 13186, 16800, 17433])].index\n",
    "df.drop(bb, inplace=True)\n",
    "cc = df[df['plan_list_price'].isin([0, 13186, 16800, 17433])].index\n",
    "df.drop(cc, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = df[df['num_25'] >= 20000].index\n",
    "df.drop(aa, inplace=True)\n",
    "bb = df[df['num_50'] >= 30000].index\n",
    "df.drop(bb, inplace=True)\n",
    "cc = df[df['num_75'] >= 10000].index\n",
    "df.drop(cc, inplace=True)\n",
    "dd = df[df['num_985'] >= 20000].index\n",
    "df.drop(dd, inplace=True)\n",
    "ee = df[df['num_100'] >= 35000].index\n",
    "df.drop(ee, inplace=True)\n",
    "ff = df[df['num_unq'] >= 24000].index\n",
    "df.drop(ff, inplace=True)\n",
    "gg = df[df['total_secs'] < 0].index\n",
    "df.drop(gg, inplace=True)\n",
    "df.drop(df[df['msno'] == 4524786].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìµœì¢… ë°ì´í„° ì…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Real_Total_Data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
