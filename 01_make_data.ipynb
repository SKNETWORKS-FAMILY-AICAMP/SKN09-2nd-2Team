{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분석용 데이터 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 다운로드 링크\n",
    "\n",
    "https://www.kaggle.com/c/kkbox-churn-prediction-challenge/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:\\\\KIMUJUNG\\\\team_project\\\\data\\\\'\n",
    "df_members = pd.read_csv(data_dir + 'members_v3.csv')\n",
    "train_v1 = pd.read_csv(data_dir + 'train.csv')\n",
    "train_v2 = pd.read_csv(data_dir + 'train_v2.csv')\n",
    "transactions_v1 = pd.read_csv(data_dir + 'transactions.csv')\n",
    "transactions_v2 = pd.read_csv(data_dir + 'transactions_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID 변수인 msno 바꿔주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_member = pd.read_csv('C:/ex_data/members_v3.csv')\n",
    "df_member_no = df_member[['msno']].copy()\n",
    "df_member_no.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_member_no['msno_encoded'] = label_encoder.fit_transform(df_member_no['msno']) + 1\n",
    "df_member_no.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# members_encoded.csv 파일 로드\n",
    "df_members = pd.read_csv('C:/ex_data/members_encoded.csv')\n",
    "\n",
    "# msno와 msno_encoded 컬럼만 추출하여 매핑 만들기\n",
    "msno_mapping = dict(zip(df_members['msno'], df_members['msno_encoded']))\n",
    "msno_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label = pd.read_csv(data_dir + 'members_encoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로그 파일 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_logs.csv 파일 로드\n",
    "df_user_logs = pd.read_csv('C:/ex_data/user_logs_v2.csv')\n",
    "\n",
    "# msno 컬럼을 msno_encoded로 변환\n",
    "df_user_logs['msno'] = df_user_logs['msno'].map(msno_mapping).astype('Int64')\n",
    "\n",
    "# csv 저장\n",
    "df_user_logs.to_csv('C:/ex_data/user_logs_v2_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_logs_v2_encoded = pd.read_csv('C:/ex_data/user_logs_v2_encoded.csv')\n",
    "df_user_logs_v2_encoded.info(), df_user_logs_v2_encoded.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user_log.csv 처리 (chunk로 분할 처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대용량 CSV를 분할 처리할 크기 (메모리 16기가면 백만, 32기가면 3백만 까지 여유로움)\n",
    "chunk_size = 1_000_000  \n",
    "output_file = \"C:/ex_data/user_logs_encoded.csv\"\n",
    "\n",
    "# CSV를 append 모드로 저장하기 위해 처음 파일 생성\n",
    "first_chunk = True  \n",
    "\n",
    "# 대용량 CSV 파일을 한 번에 다 읽지 않고 부분적으로 처리\n",
    "for chunk in pd.read_csv(\"C:/ex_data/user_logs.csv\", chunksize=chunk_size):\n",
    "    chunk['msno'] = chunk['msno'].map(msno_mapping).astype('Int64')  # msno를 정수형으로 변환\n",
    "\n",
    "    # 변환된 데이터를 CSV 파일로 저장 (첫 번째 반복에서는 헤더 포함, 이후에는 생략)\n",
    "    chunk.to_csv(output_file, index=False, mode='w' if first_chunk else 'a', header=first_chunk)\n",
    "    \n",
    "    first_chunk = False  # 이후에는 'append' 모드로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2GB씩 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스에서 실행할려면 파일 크기가 2GB 제한\n",
    "chunk_size = 50_000_000  \n",
    "file_index = 1  # 파일 번호\n",
    "\n",
    "for chunk in pd.read_csv(\"C:/ex_data/user_logs_encoded.csv\", chunksize=chunk_size):\n",
    "    output_file = f\"C:/ex_data/user_logs_encoded_part{file_index}.csv\"\n",
    "    chunk.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"파일 저장 완료: {output_file}\")  # 저장 완료 메시지 출력\n",
    "    file_index += 1  # 다음 파일 번호 증가\n",
    "\n",
    "print('파일 분할 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환할 파일 리스트\n",
    "file_list = [f\"C:/ex_data/user_logs_encoded_part{i}.csv\" for i in range(1, 9)]\n",
    "\n",
    "for file in file_list:\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # msno 컬럼을 Int64로 변환\n",
    "    df['msno'] = df['msno'].astype('Int64')\n",
    "\n",
    "    # 다시 저장 (덮어쓰기)\n",
    "    df.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"변환 완료: {file}\")\n",
    "\n",
    "print(\"모든 파일의 msno를 Int64로 변환 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = pd.read_csv(\"C:/ex_data/user_logs_encoded_part7.csv\")\n",
    "split_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# 파일 경로 리스트 (user_logs_v2_encoded.csv + user_logs_encoded_part*.csv 포함)\n",
    "file_list = [\"C:/ex_data/user_logs_v2_encoded.csv\"] + glob.glob(\"C:/ex_data/user_logs_encoded_part*.csv\")\n",
    "\n",
    "# msno별 데이터를 저장할 딕셔너리 (메모리 절약)\n",
    "aggregated_data = {}\n",
    "\n",
    "# 각 파일을 청크 단위로 읽어서 그룹화 & 누적\n",
    "for file in file_list:\n",
    "    print(f\"파일 처리 중: {file}\")\n",
    "\n",
    "    # CSV 파일 읽기 (청크 단위 처리)\n",
    "    for chunk in pd.read_csv(file, chunksize=3_000_000):  # 청크 크기 조절 가능\n",
    "        # msno 기준으로 그룹화하여 데이터 합산\n",
    "        grouped = chunk.groupby(\"msno\").agg(\n",
    "            num_25=(\"num_25\", \"sum\"),\n",
    "            num_50=(\"num_50\", \"sum\"),\n",
    "            num_75=(\"num_75\", \"sum\"),\n",
    "            num_985=(\"num_985\", \"sum\"),\n",
    "            num_100=(\"num_100\", \"sum\"),\n",
    "            num_unq=(\"num_unq\", \"sum\"),\n",
    "            total_secs=(\"total_secs\", \"sum\"),\n",
    "            log_start=(\"date\", \"min\"),  # 가장 빠른 날짜\n",
    "            log_end=(\"date\", \"max\")  # 가장 마지막 날짜\n",
    "        ).reset_index()\n",
    "\n",
    "        # 🏗 기존 데이터와 병합하여 누적 (딕셔너리를 활용한 병합)\n",
    "        for row in grouped.itertuples(index=False):\n",
    "            msno = row.msno\n",
    "            if msno in aggregated_data:\n",
    "                aggregated_data[msno][\"num_25\"] += row.num_25\n",
    "                aggregated_data[msno][\"num_50\"] += row.num_50\n",
    "                aggregated_data[msno][\"num_75\"] += row.num_75\n",
    "                aggregated_data[msno][\"num_985\"] += row.num_985\n",
    "                aggregated_data[msno][\"num_100\"] += row.num_100\n",
    "                aggregated_data[msno][\"num_unq\"] += row.num_unq\n",
    "                aggregated_data[msno][\"total_secs\"] += row.total_secs\n",
    "                aggregated_data[msno][\"log_start\"] = min(aggregated_data[msno][\"log_start\"], row.log_start)\n",
    "                aggregated_data[msno][\"log_end\"] = max(aggregated_data[msno][\"log_end\"], row.log_end)\n",
    "            else:\n",
    "                aggregated_data[msno] = {\n",
    "                    \"num_25\": row.num_25,\n",
    "                    \"num_50\": row.num_50,\n",
    "                    \"num_75\": row.num_75,\n",
    "                    \"num_985\": row.num_985,\n",
    "                    \"num_100\": row.num_100,\n",
    "                    \"num_unq\": row.num_unq,\n",
    "                    \"total_secs\": row.total_secs,\n",
    "                    \"log_start\": row.log_start,\n",
    "                    \"log_end\": row.log_end\n",
    "                }\n",
    "\n",
    "# 딕셔너리를 DataFrame으로 변환 (msno를 컬럼으로 유지)\n",
    "df_final = pd.DataFrame.from_dict(aggregated_data, orient=\"index\")\n",
    "\n",
    "# msno를 일반 컬럼으로 유지하고 인덱스 제거\n",
    "df_final.index.name = \"msno\"\n",
    "df_final.reset_index(inplace=True)\n",
    "\n",
    "# CSV 파일로 저장 (인덱스 없이)\n",
    "df_final.to_csv(\"C:/ex_data/user_logs_summary.csv\", index=False)\n",
    "\n",
    "print(\"저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = pd.read_csv(data_dir + 'user_logs_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v1['version'] = 'v1'\n",
    "train_v2['version'] = 'v2'\n",
    "train = pd.concat([train_v1, train_v2])\n",
    "train = train.sort_values(['msno', 'version'], ascending = [True, False]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = train['msno'][(train['is_churn'] == 0) & (train['version'] == 'v2')]\n",
    "bb = train['msno'][(train['is_churn'] == 1) & (train['version'] == 'v1')]\n",
    "cc = list(set(aa) & set(bb))\n",
    "train['is_back'] = train['msno'].isin(cc).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복값을 제거하되, 중복 Row 중 첫번째 Row를 남기는 옵션을 선택함\n",
    "train.drop_duplicates(subset='msno', keep='first', inplace=True)\n",
    "train.query('msno in \"+++hVY1rZox/33YtvDgmKA2Frg/2qhkz12B9ylCvh8o=\"')\n",
    "# version 컬럼 제거\n",
    "train = train.drop('version', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transaction 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구매 기록 데이터 합치기\n",
    "transactions = pd.concat([transactions_v1, transactions_v2], ignore_index=True)\n",
    "transactions = transactions.sort_values(['msno', 'transaction_date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0으로 나누는 오류 방지: plan_list_price가 0인 경우는 NaN 처리\n",
    "transactions[\"discount_rate\"] = np.where(\n",
    "    transactions[\"plan_list_price\"] != 0, \n",
    "    1 - (transactions[\"actual_amount_paid\"] / transactions[\"plan_list_price\"]),\n",
    "    np.nan  # 원래 가격이 0이면 NaN (이후 평균 계산 시 자동 제외됨)\n",
    ")\n",
    "\n",
    "# 사용자 ID(msno) 기준으로 그룹화하여 새로운 데이터프레임 생성\n",
    "df_transaction = transactions.groupby(\"msno\").agg(\n",
    "    payment_plan_sum=(\"payment_plan_days\", \"sum\"),\n",
    "    plan_list_price=(\"plan_list_price\", \"sum\"),\n",
    "    actual_amount_paid=(\"actual_amount_paid\", \"sum\"),\n",
    "    discount_rate=(\"discount_rate\", \"mean\"),  # 개별 거래별 할인율 평균\n",
    "    is_auto_renew=(\"is_auto_renew\", \"mean\"),\n",
    "    membership_expire_date=(\"membership_expire_date\", \"max\"),\n",
    "    is_cancel=(\"is_cancel\", \"mean\"),\n",
    "    transaction_count=(\"msno\", \"count\")\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터프레임에 msno_num 추가\n",
    "train_en = train.merge(unique_label, on='msno', how='inner').drop(columns=['msno'])\n",
    "members_en = df_members.merge(unique_label, on='msno', how='inner').drop(columns=['msno'])\n",
    "df_transaction_en = df_transaction.merge(unique_label, on='msno', how='inner').drop(columns=['msno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkbox_transaction_merge = pd.merge(train_en, df_transaction_en, on='msno_encoded', how='inner',)\n",
    "kkbox_merge = pd.merge(members_en, kkbox_transaction_merge, on='msno_encoded', how='inner')\n",
    "kkbox_merge['msno'] = kkbox_merge['msno_encoded']\n",
    "kkbox_merge = kkbox_merge[['msno', 'city', 'bd', 'gender', 'registered_via', 'registration_init_time',\n",
    "        'is_churn', 'is_back', 'payment_plan_sum',\n",
    "        'plan_list_price', 'actual_amount_paid', 'discount_rate',\n",
    "        'is_auto_renew', 'membership_expire_date', 'is_cancel', 'transaction_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkbox_merge_final = pd.merge(kkbox_merge, log_data, on='msno', how='inner')\n",
    "kkbox_merge_final.to_csv(data_dir + \"kkbox_data_total.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성별 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir + 'kkbox_data_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(df):\n",
    "    # membership_expire_date와 registration_init_time은 'YYYY-MM-DD' 형식으로 되어 있으므로, 그에 맞춰 변환\n",
    "    df['membership_expire_date'] = pd.to_datetime(df['membership_expire_date'], errors='coerce')\n",
    "    df['registration_init_time'] = pd.to_datetime(df['registration_init_time'], errors='coerce')\n",
    "    \n",
    "    # log_start와 log_end는 'YYYYMMDD' 형식이므로, 그에 맞춰 변환\n",
    "    df['log_start'] = pd.to_datetime(df['log_start'].astype(str), format='%Y%m%d', errors='coerce')\n",
    "    df['log_end'] = pd.to_datetime(df['log_end'].astype(str), format='%Y%m%d', errors='coerce')\n",
    "\n",
    "    # 등록기간 계산: membership_expire_date와 registration_init_time 차이\n",
    "    df['registration_duration'] = (df['membership_expire_date'] - df['registration_init_time']).dt.days\n",
    "\n",
    "    # 음악 청취 기간 계산: log_end와 log_start 차이\n",
    "    df['listening_duration'] = (df['log_end'] - df['log_start']).dt.days\n",
    "\n",
    "    # 필요 없는 컬럼 삭제\n",
    "    df.drop(['membership_expire_date', 'registration_init_time', 'log_start', 'log_end'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# 함수 실행\n",
    "df = duration(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['gender'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_gender(df):\n",
    "    # 성별 인코딩: M -> 1, F -> 0, nan -> -1 (또는 원하는 값으로 변경)\n",
    "    df['gender'] = df['gender'].map({'male': 1, 'female': 0})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode_gender(df)\n",
    "df['gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나이 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"bd\"] = df[\"bd\"].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"bd\"] >= 10) & (df[\"bd\"] <= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0', 'is_back', 'msno'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이상치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = df[df['payment_plan_sum'].isin([0, 2882, 3550])].index\n",
    "df.drop(aa, inplace=True)\n",
    "bb = df[df['plan_list_price'].isin([0, 13186, 16800, 17433])].index\n",
    "df.drop(bb, inplace=True)\n",
    "cc = df[df['plan_list_price'].isin([0, 13186, 16800, 17433])].index\n",
    "df.drop(cc, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = df[df['num_25'] >= 20000].index\n",
    "df.drop(aa, inplace=True)\n",
    "bb = df[df['num_50'] >= 30000].index\n",
    "df.drop(bb, inplace=True)\n",
    "cc = df[df['num_75'] >= 10000].index\n",
    "df.drop(cc, inplace=True)\n",
    "dd = df[df['num_985'] >= 20000].index\n",
    "df.drop(dd, inplace=True)\n",
    "ee = df[df['num_100'] >= 35000].index\n",
    "df.drop(ee, inplace=True)\n",
    "ff = df[df['num_unq'] >= 24000].index\n",
    "df.drop(ff, inplace=True)\n",
    "gg = df[df['total_secs'] < 0].index\n",
    "df.drop(gg, inplace=True)\n",
    "df.drop(df[df['msno'] == 4524786].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Real_Total_Data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
